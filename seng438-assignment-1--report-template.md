>   **SENG 438 - Software Testing, Reliability, and Quality**

**Lab. Report \#1 – Introduction to Testing and Defect Tracking**

| Group \#:    |  12 |
|-----------------|---|
| Student Names:  | Asma Hashmi  |
|                 | Hasan Mahtab  | 
|                 | Hesham Elkalioub   |
|                 | Dagvadorj (Tom) Altankhuyag  |

**Table of Contents**

(When you finish writing, update the following list using right click, then
“Update Field”)

[1 Introduction	1](#_Toc439194677)

[2 High-level description of the exploratory testing plan	1](#_Toc439194678)

[3 Comparison of exploratory and manual functional testing	1](#_Toc439194679)

[4 Notes and discussion of the peer reviews of defect reports	1](#_Toc439194680)

[5 How the pair testing was managed and team work/effort was
divided	1](#_Toc439194681)

[6 Difficulties encountered, challenges overcome, and lessons
learned	1](#_Toc439194682)

[7 Comments/feedback on the lab and lab document itself	1](#_Toc439194683)

# Introduction

The objective of this assignment is to gain real world understanding of three different testing styles: Exploratory, Scripted, and Regression Testing. These three test styles were deployed on a sample ATM testing app designed for the purpose of these tests. For example, there were two .jar files given for version 1.0 and version 1.1. This was to be able to do Regression Testing between the two versions and expose other bugs that may have occurred during development.

Going into this lab, the group had introductory knowledge about these three different testing styles from our SENG 438 lectures. While performing this lab we did not learn any further concepts regarding these test styles. However, we learned how to use the Backlog service to track bugs. And, we got some experience into how real world bug reports are drafted.


# High-level description of the exploratory testing plan

Go through every menu option through both accounts and test their functions. For example, for account one, we test all available options with valid and invalid inputs after we log in and turn on the ATM machine. 


# Comparison of exploratory and manual functional testing

In a real world scenario, Manual Function testing would be scripted, but in this case we were not using scripts. Thus, Exploratory and Manual Function testing were identical in our testing since our Exploratory Testing plan covered all of the Manual Function Testing cases. 


# Notes and discussion of the peer reviews of defect reports

Tom and Hesham:
We communicated an agreed upon format before beginning our bug testing that we would use. Furthermore, when the assignment document mentioned version numbers, we noticed that there was no field to input these so we decided to add them into our title.

Asma and Hasan:
We decided to split up the 40 test cases for the Manual Function Testing. We both took 20 test cases each and began testing. As for the Exploratory Testing, as we were going through our assigned test cases, we were able to catch other errors as well. These were all recorded on the Backlog.

Pair evaluations:
Each pair had an idea about the format that they wanted to use for the defect reports. Thus, we communicated with each other and came up with the most suitable format we could think of based on the assignment requirements. An issue we ran into before our demonstration was that we neglected to include the priority and severity of each bug in its report. This was easily solved and communicated in our group as we each went back and assigned each report these values.


# How the pair testing was managed and team work/effort was divided 

Tom and Hesham:
We learned how to motivate each other to continue working hard through some repetitive test cases. Additionally, working in pairs allowed us to brainstorm different invalid inputs and test cases to attempt. Thus, working in pairs allows for the evolution of ideas that would have not otherwise happened when working individually.

Asma and Hasan
We were able to do problem-solving right away when working on the 40 test cases. This allowed us to complete the three types of testing quickly. Additionally, we were able to discuss and confirm test case outputs if there was any confusion.



# Difficulties encountered, challenges overcome, and lessons learned

The biggest challenge was learning how to use the Backlog service to track bugs. In some cases, the user interface is not refined and requires additional focus to do some basic actions such as editing tasks in groups, and deleting tasks. Additionally, when we were going through the test cases, occasionally the GUI would freeze up, leading us to think there was an error with our command. We would have to re-open the GUI to confirm this and proceed before recording it down on Backlog.


# Comments/feedback on the lab and lab document itself

The ATM banking application added an interesting novelty aspect to the lab which made it more fun.

